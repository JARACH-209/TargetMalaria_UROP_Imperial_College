{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12ff454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import allel\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, precision_score, accuracy_score, cohen_kappa_score, f1_score\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "475823fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_SEED = 22\n",
    "home = os.path.expanduser('~')\n",
    "directory = os.path.join('Imp_Research','Dataset')\n",
    "\n",
    "# populations = ['BFcol','BFgam','AOcol','CIcol','CMgam','FRgam',\n",
    "#               'GAgam','GHcol','GHgam','GM','GNcol','GNgam','GQgam',\n",
    "#               'GW','KE','UGgam']\n",
    "\n",
    "# Using only 12 populations out of 16\n",
    "populations = ['BFcol','BFgam','AOcol','CIcol','CMgam',\n",
    "              'GAgam','GHcol','GM','GNgam','GW','KE','UGgam']\n",
    "\n",
    "# Creating a dictionary of Population names with labels\n",
    "populations_labels = {}\n",
    "for i in range(len(populations)):\n",
    "    populations_labels[i] = populations[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6de46a",
   "metadata": {},
   "source": [
    "### Functions to Load and Pre-Process the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a390ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Requirements : NumPy and Scikit-Allel\n",
    "'''\n",
    "\n",
    "class FilterSNP():\n",
    "    def __init__(self,haplotype, POS):\n",
    "        self.haplotype = haplotype\n",
    "        self.POS = POS\n",
    "        self.H = haplotype\n",
    "        self.P = POS\n",
    "        self._removed_maf = None\n",
    "        self._retained_maf = None\n",
    "        self._retained_ld = None\n",
    "        self._removed_ld = None\n",
    "        self._unlinked_POS = None\n",
    "        \n",
    "    def all_filters(self, LD_window_size, LD_overlap_step, MBP_start = 1, MBP_end = 37, MAF_threshold = 5, LD_threshold=.1,LD_iter=1):\n",
    "        print(\"1.) Selecting Mega Base Pairs\")\n",
    "        self.H,self.P = self.get_haplo_MBP(self.H,self.P,start = MBP_start, end = MBP_end)\n",
    "        print(\"MBP selected. Retained Matrix = \", self.H.shape)\n",
    "        print(\"2.) Filtering Rare Allels\")\n",
    "        self.H,self.P = self.filter_MAF(self.H,self.P,threshold = MAF_threshold)\n",
    "        print(\"3.) Performing LD Pruning\")\n",
    "        self.H,self.P = self.LD_pruning(self.H, self.P, LD_window_size, LD_overlap_step, threshold = LD_threshold, n_iter = LD_iter)\n",
    "        print(\"Retained Haplotype Matrix = \", self.H.shape)\n",
    "        print(\"Retained Positions Matrix = \",self.P.shape)\n",
    "        \n",
    "        return self.H, self.P\n",
    "        \n",
    "    # input dimensions for Haplotype matrix (gn) = SNP X n\n",
    "    def filter_MAF(self,haplo,POS,threshold = 5):\n",
    "        if threshold >= 50 : \n",
    "            print(\"MAF threshold cannot be more than 49%\")\n",
    "            return\n",
    "        samples = haplo.shape[1]\n",
    "        sums = haplo.sum(axis=1)\n",
    "        maf = self.get_MAF(haplo)\n",
    "        #indexes = np.where(maf >= threshold*0.01)[0]\n",
    "        minor = samples*threshold/100\n",
    "        major = samples*(100-threshold)/100\n",
    "        # Selects indexes where allels are >threshold or all 0 and all 1.\n",
    "        indexes = np.where((sums>=minor)& (sums<=major))[0]\n",
    "        print(\"Number of SNPs removed = \",len(haplo)-len(indexes))\n",
    "        print(\"Retaining = \",len(indexes))\n",
    "        self._removed_maf = len(haplo)-len(indexes)\n",
    "        self._retained_maf = len(indexes)\n",
    "        return np.take(haplo,indexes,0), np.take(POS,indexes,0)\n",
    "\n",
    "    # Returns : Array of MAF\n",
    "    # input dimensions for Haplotype matrix (gn) = SNP X n\n",
    "    def get_MAF(self,haplo):\n",
    "        samples = haplo.shape[1]\n",
    "        sums = haplo.sum(axis=1)\n",
    "        maf = []\n",
    "        for s in sums:\n",
    "            if s != samples or s != 0:\n",
    "                frequency = s/samples\n",
    "                if frequency > 0.5:\n",
    "                    maf.append(1-frequency)\n",
    "                else: \n",
    "                    maf.append(frequency)\n",
    "        return np.array(maf)\n",
    "\n",
    "    # input dimensions for Haplotype matrix (gn) = SNP X n\n",
    "    def get_MBP(self,POS,start = 1,end = 37):\n",
    "        return np.where(POS[np.where(POS>=1e6)]<=37e6)[0]\n",
    "\n",
    "    # input dimensions for Haplotype matrix (gn) = SNP X n\n",
    "    def get_haplo_MBP(self,haplotype,POS,start = 1,end = 37):\n",
    "        index = self.get_MBP(POS,start,end)\n",
    "        return np.take(haplotype,index,0),np.take(POS,index,0)\n",
    "    \n",
    "    # input dimensions for Haplotype matrix (gn) = SNP X n\n",
    "    def LD_pruning(self, gn, pos, size, step, threshold = .1, n_iter=1):\n",
    "        removed = 0\n",
    "        for i in range(n_iter):\n",
    "            \n",
    "            # Returns a boolean array. True(1) - SNPs are within threshold (Unliked), False(0) = Linked\n",
    "            loc_unlinked = allel.locate_unlinked(gn, size=size, step=step, threshold=threshold)\n",
    "            \n",
    "            # Counts non-zero elements = No. of unlinked loci or SNPs to retain\n",
    "            n = np.count_nonzero(loc_unlinked)\n",
    "            \n",
    "            # Calculate the number of SNPs to be removed\n",
    "            n_remove = gn.shape[0] - n\n",
    "            removed += n_remove\n",
    "            print('iteration', i+1, 'retaining', n, 'removing', n_remove, 'variants')\n",
    "            \n",
    "            # Select only the unlinked SNPs, i.e., indexes where value is True(1).\n",
    "            gn = gn.compress(loc_unlinked, axis=0)\n",
    "            \n",
    "            # retaining the indexes preserved\n",
    "            pos = pos.compress(loc_unlinked)\n",
    "        self._retained_ld = gn.shape[0]\n",
    "        self._removed_ld = removed\n",
    "        self._unlinked_POS = pos\n",
    "        return gn,pos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
